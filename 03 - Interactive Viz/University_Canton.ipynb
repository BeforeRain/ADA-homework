{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"# Step 1. Process data\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TODO: Following given notebooks in HW1, create table of contents here :) </a></div>\n",
    "\n",
    "This Jupyter extension might help. https://github.com/minrk/ipython_extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 03 - Interactive Viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "\n",
    "### Objective : Build a [Choropleth map](https://en.wikipedia.org/wiki/Choropleth_map) which shows intuitively how much grant money goes to each Swiss canton.\n",
    "\n",
    "##### What data do we have?\n",
    "\n",
    "The SNSF (Swiss National Science Foundation) has graciously provided the [P<sup>3</sup>](http://p3.snf.ch/) database, which contains data on research projects approved by the SNSF. We will just use the [Grants Data](http://p3.snf.ch/P3Export/P3_GrantExport.csv) (saved in `data/P3_GrantExport`) as this contains the grant amounts going to different universities.\n",
    "\n",
    "We are also given the file `data/ch-cantons.topojson.json`, which contains the geo-coordinates of each Swiss canton.\n",
    "\n",
    "##### What needs to be done?\n",
    "\n",
    "The Grants Data does not contain the Canton of the University/Institution that received the funding. Therefore, we will need to deduce the Canton from the University/Institution. Once this is accomplished, we can sum the grant money that was allocated to each Canton.\n",
    "\n",
    "##### How will this be done?\n",
    "\n",
    "We will use the following Python packages to accomplish our objective:\n",
    "1. `pandas` to import, clean, and wrangle the Grants Data\n",
    "2. `json` and `pprint` to read the `data/ch-cantons.topojson.json` file\n",
    "3. `requests` with the [GeoNames API](http://www.geonames.org/export/web-services.html) and `googlemaps` (a [Python wrapper](https://github.com/googlemaps/google-maps-services-python) for Google Maps API Web Services) to determine the Canton of a particular University/Institution\n",
    "4. `folium` to deal with the geographical data and create the Choropleth map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Choropleth Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by importing the Python packages mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the Data\n",
    "\n",
    "We downloaded the [Grants Data](http://p3.snf.ch/P3Export/P3_GrantExport.csv) and placed it in the local `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿\"Project Number\"</th>\n",
       "      <th>Project Title</th>\n",
       "      <th>Project Title English</th>\n",
       "      <th>Responsible Applicant</th>\n",
       "      <th>Funding Instrument</th>\n",
       "      <th>Funding Instrument Hierarchy</th>\n",
       "      <th>Institution</th>\n",
       "      <th>University</th>\n",
       "      <th>Discipline Number</th>\n",
       "      <th>Discipline Name</th>\n",
       "      <th>Discipline Name Hierarchy</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Approved Amount</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Schlussband (Bd. VI) der Jacob Burckhardt-Biog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaegi Werner</td>\n",
       "      <td>Project funding (Div. I-III)</td>\n",
       "      <td>Project funding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nicht zuteilbar - NA</td>\n",
       "      <td>10302</td>\n",
       "      <td>Swiss history</td>\n",
       "      <td>Human and Social Sciences;Theology &amp; religious...</td>\n",
       "      <td>01.10.1975</td>\n",
       "      <td>30.09.1976</td>\n",
       "      <td>11619.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Batterie de tests à l'usage des enseignants po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massarenti Léonard</td>\n",
       "      <td>Project funding (Div. I-III)</td>\n",
       "      <td>Project funding</td>\n",
       "      <td>Faculté de Psychologie et des Sciences de l'Ed...</td>\n",
       "      <td>Université de Genève - GE</td>\n",
       "      <td>10104</td>\n",
       "      <td>Educational science and Pedagogy</td>\n",
       "      <td>Human and Social Sciences;Psychology, educatio...</td>\n",
       "      <td>01.10.1975</td>\n",
       "      <td>30.09.1976</td>\n",
       "      <td>41022.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Kritische Erstausgabe der \"Evidentiae contra D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kommission für das Corpus philosophorum medii ...</td>\n",
       "      <td>Project funding (Div. I-III)</td>\n",
       "      <td>Project funding</td>\n",
       "      <td>Kommission für das Corpus philosophorum medii ...</td>\n",
       "      <td>NPO (Biblioth., Museen, Verwalt.) - NPO</td>\n",
       "      <td>10101</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Human and Social Sciences;Linguistics and lite...</td>\n",
       "      <td>01.03.1976</td>\n",
       "      <td>28.02.1985</td>\n",
       "      <td>79732.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿\"Project Number\"                                      Project Title  \\\n",
       "0                  1  Schlussband (Bd. VI) der Jacob Burckhardt-Biog...   \n",
       "1                  4  Batterie de tests à l'usage des enseignants po...   \n",
       "2                  5  Kritische Erstausgabe der \"Evidentiae contra D...   \n",
       "\n",
       "  Project Title English                              Responsible Applicant  \\\n",
       "0                   NaN                                       Kaegi Werner   \n",
       "1                   NaN                                 Massarenti Léonard   \n",
       "2                   NaN  Kommission für das Corpus philosophorum medii ...   \n",
       "\n",
       "             Funding Instrument Funding Instrument Hierarchy  \\\n",
       "0  Project funding (Div. I-III)              Project funding   \n",
       "1  Project funding (Div. I-III)              Project funding   \n",
       "2  Project funding (Div. I-III)              Project funding   \n",
       "\n",
       "                                         Institution  \\\n",
       "0                                                NaN   \n",
       "1  Faculté de Psychologie et des Sciences de l'Ed...   \n",
       "2  Kommission für das Corpus philosophorum medii ...   \n",
       "\n",
       "                                University  Discipline Number  \\\n",
       "0                     Nicht zuteilbar - NA              10302   \n",
       "1                Université de Genève - GE              10104   \n",
       "2  NPO (Biblioth., Museen, Verwalt.) - NPO              10101   \n",
       "\n",
       "                    Discipline Name  \\\n",
       "0                     Swiss history   \n",
       "1  Educational science and Pedagogy   \n",
       "2                        Philosophy   \n",
       "\n",
       "                           Discipline Name Hierarchy  Start Date    End Date  \\\n",
       "0  Human and Social Sciences;Theology & religious...  01.10.1975  30.09.1976   \n",
       "1  Human and Social Sciences;Psychology, educatio...  01.10.1975  30.09.1976   \n",
       "2  Human and Social Sciences;Linguistics and lite...  01.03.1976  28.02.1985   \n",
       "\n",
       "  Approved Amount Keywords  \n",
       "0        11619.00      NaN  \n",
       "1        41022.00      NaN  \n",
       "2        79732.00      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRANTS_FILE = 'data/P3_GrantExport.csv'\n",
    "grants_data_orig = pd.read_csv(GRANTS_FILE, sep = ';')\n",
    "grants_data_orig.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our objective, we are interested in the following columns: \n",
    "\n",
    "* ** University **: the (possible) university proposing the project. As we see in the third row, a grant can be awarded to an NPO (Non-Profit Organization).\n",
    "* ** Institution **: the institution proposing the project.\n",
    "* ** Approved Amount **: amount of approved grants\n",
    "\n",
    "The Institution/University can be used to deduce the Swiss Canton. Finally, the Amount Approved will be used for our Choropleth map. Let's extract these columns to reduce the size of our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Approved Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicht zuteilbar - NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11619.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Université de Genève - GE</td>\n",
       "      <td>Faculté de Psychologie et des Sciences de l'Ed...</td>\n",
       "      <td>41022.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NPO (Biblioth., Museen, Verwalt.) - NPO</td>\n",
       "      <td>Kommission für das Corpus philosophorum medii ...</td>\n",
       "      <td>79732.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universität Basel - BS</td>\n",
       "      <td>Abt. Handschriften und Alte Drucke Bibliothek ...</td>\n",
       "      <td>52627.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NPO (Biblioth., Museen, Verwalt.) - NPO</td>\n",
       "      <td>Schweiz. Thesauruskommission</td>\n",
       "      <td>120042.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                University  \\\n",
       "0                     Nicht zuteilbar - NA   \n",
       "1                Université de Genève - GE   \n",
       "2  NPO (Biblioth., Museen, Verwalt.) - NPO   \n",
       "3                   Universität Basel - BS   \n",
       "4  NPO (Biblioth., Museen, Verwalt.) - NPO   \n",
       "\n",
       "                                         Institution Approved Amount  \n",
       "0                                                NaN        11619.00  \n",
       "1  Faculté de Psychologie et des Sciences de l'Ed...        41022.00  \n",
       "2  Kommission für das Corpus philosophorum medii ...        79732.00  \n",
       "3  Abt. Handschriften und Alte Drucke Bibliothek ...        52627.00  \n",
       "4                       Schweiz. Thesauruskommission       120042.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grants_data_red = grants_data_orig[['University', 'Institution', 'Approved Amount']]\n",
    "grants_data_red.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will rename the \"Approved Amount\" column to \"Amount\" so that it can be easily accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grants_data_red = grants_data_red.rename(columns={'Approved Amount': 'Amount'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning \"Amount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the \"Amount\" has the correct variable type, i.e. numeric, and that entries with an invalid \"Amount\" are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63969, 3)\n",
      "(53059, 3)\n"
     ]
    }
   ],
   "source": [
    "print(grants_data_red.shape)\n",
    "grants_clean_amount = grants_data_red\n",
    "grants_clean_amount.Amount = pd.to_numeric(grants_clean_amount.Amount, errors='coerce')\n",
    "grants_clean_amount = grants_data_red.dropna(subset=[\"Amount\"])\n",
    "print(grants_clean_amount.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have dropped 10910 entries.\n",
    "\n",
    "### Cleaning \"University\" and \"Institution\"\n",
    "\n",
    "We only need one of these fields to be valid for each row in order to geolocate where the grant was awarded. So let's drop those rows that have invalid entries for **both** fields. Moreover, we have noticed that the \"University\" entries have the following structure:\n",
    "\n",
    "`LONG NAME - SHORT NAME`\n",
    "\n",
    "Furthermore, one of the entries is `Nicht zuteilbar - NA` which must be SNSF's way of indicating an invalid entry. We will first replace such entries with the standard entry for invalids - `NaN` - before dropping rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53059, 3)\n",
      "(49823, 3)\n"
     ]
    }
   ],
   "source": [
    "print(grants_clean_amount.shape)\n",
    "grants_clean_place = grants_clean_amount.replace(to_replace=\"Nicht zuteilbar - NA\", value=nan)\n",
    "grants_clean_place.dropna(how='all',subset=[\"University\",\"Institution\"], inplace=True)\n",
    "print(grants_clean_place.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# suppressed output for shorter notebook!\n",
    "#grants_clean_place.University.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have dropped 3236 entries. Almost done! We only one need either \"Univerisity\" or \"Institution\" for geolocation. For most entries the \"University\" should be enough. However, 1437 of the entries are not from Universities but rather Non-Profit Organizations (NPO) and there are 1540 `NaN`s. This count was determined by running:\n",
    "\n",
    "`grants_clean_place.University.value_counts(dropna=False)`\n",
    "\n",
    "We will modify the \"University\" column by setting its value to `NaN` if the entry is \"NPO (Biblioth., Museen, Verwalt.) - NPO\". For the valid universities, we will decouple the `LONG NAME` and `SHORT NAME` and place them in different columns. These modifications will make it easier later on when mapping the university/institution to a Canton and for checking the criteria that 95% of the universities are mapped to a canton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_short_name(row):\n",
    "    # extract the SHORT NAME from University\n",
    "    uni = str(row[\"University\"])\n",
    "    if uni == \"NPO (Biblioth., Museen, Verwalt.) - NPO\" or pd.isnull(uni):\n",
    "        return np.nan\n",
    "    split_entry = uni.split()\n",
    "    return split_entry[-1]\n",
    "\n",
    "def extract_long_name(entry):\n",
    "    # extract the LONG NAME and remove the space at the end\n",
    "    split_entry = entry.rsplit(\"-\",1)\n",
    "    return split_entry[0].rstrip()\n",
    "\n",
    "def modify_university(row): \n",
    "    # keep long name unless it is an NPO or NaN\n",
    "    if row[\"University\"] == \"NPO (Biblioth., Museen, Verwalt.) - NPO\" or pd.isnull(row[\"University\"]):\n",
    "        return np.nan\n",
    "    else: \n",
    "        return extract_long_name(str(row[\"University\"]))\n",
    "\n",
    "grants_modified_uni = grants_clean_place.copy()\n",
    "grants_modified_uni['Short'] = grants_modified_uni.apply(lambda row: extract_short_name(row), axis=1)\n",
    "grants_modified_uni['University'] = grants_modified_uni.apply(lambda row: modify_university(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Université de Genève</td>\n",
       "      <td>Faculté de Psychologie et des Sciences de l'Ed...</td>\n",
       "      <td>41022.0</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Kommission für das Corpus philosophorum medii ...</td>\n",
       "      <td>79732.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Universität Basel</td>\n",
       "      <td>Abt. Handschriften und Alte Drucke Bibliothek ...</td>\n",
       "      <td>52627.0</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Schweiz. Thesauruskommission</td>\n",
       "      <td>120042.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Université de Fribourg</td>\n",
       "      <td>Séminaire de politique économique, d'économie ...</td>\n",
       "      <td>53009.0</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               University                                        Institution  \\\n",
       "1    Université de Genève  Faculté de Psychologie et des Sciences de l'Ed...   \n",
       "2                     NaN  Kommission für das Corpus philosophorum medii ...   \n",
       "3       Universität Basel  Abt. Handschriften und Alte Drucke Bibliothek ...   \n",
       "4                     NaN                       Schweiz. Thesauruskommission   \n",
       "5  Université de Fribourg  Séminaire de politique économique, d'économie ...   \n",
       "\n",
       "     Amount Short  \n",
       "1   41022.0    GE  \n",
       "2   79732.0   NaN  \n",
       "3   52627.0    BS  \n",
       "4  120042.0   NaN  \n",
       "5   53009.0    FR  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grants_modified_uni.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We have gone from 63696 entries to 49823 by dropping invalid \"Amount\" and \"University\" or \"Institution\" entries. We have also re-labelled data (NPO to `NaN` and decoupled the long and short name of the university for our convenience in analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading the Canton Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we obtain the abbrevations for all cantons from the geographical JSON data in `data/ch-cantons.topojson.json`. We did some inspection of the structure of the JSON file (using pprint) and extracted the canton abbrevations by navigating appropriately through the JSON data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZH', 'BE', 'LU', 'UR', 'SZ', 'OW', 'NW', 'GL', 'ZG', 'FR', 'SO', 'BS', 'BL', 'SH', 'AR', 'AI', 'SG', 'GR', 'AG', 'TG', 'TI', 'VD', 'VS', 'NE', 'GE', 'JU']\n"
     ]
    }
   ],
   "source": [
    "CH_GEO_JSON = 'data/ch-cantons.topojson.json'\n",
    "\n",
    "with open(CH_GEO_JSON, 'r') as f:\n",
    "    canton_data = json.load(f)\n",
    "\n",
    "cantons = canton_data['objects']['cantons']['geometries']\n",
    "canton_ids = []\n",
    "for canton in cantons:\n",
    "    canton_ids.append(canton['id'])\n",
    "\n",
    "print(canton_ids)\n",
    "#pprint(canton_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mapping \"Institute\" to a Canton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Python wrapper for geolocating the Universities and Institutions. Let's see how it works for `EPFL` so we know how to parse its result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'address_components': [{'long_name': 'EPFL',\n",
       "    'short_name': 'EPFL',\n",
       "    'types': ['premise']},\n",
       "   {'long_name': 'Lausanne',\n",
       "    'short_name': 'Lausanne',\n",
       "    'types': ['locality', 'political']},\n",
       "   {'long_name': 'Ouest lausannois',\n",
       "    'short_name': 'Ouest lausannois',\n",
       "    'types': ['administrative_area_level_2', 'political']},\n",
       "   {'long_name': 'Vaud',\n",
       "    'short_name': 'VD',\n",
       "    'types': ['administrative_area_level_1', 'political']},\n",
       "   {'long_name': 'Switzerland',\n",
       "    'short_name': 'CH',\n",
       "    'types': ['country', 'political']},\n",
       "   {'long_name': '1015', 'short_name': '1015', 'types': ['postal_code']}],\n",
       "  'formatted_address': 'EPFL, 1015 Lausanne, Switzerland',\n",
       "  'geometry': {'location': {'lat': 46.5189865, 'lng': 6.5676007},\n",
       "   'location_type': 'ROOFTOP',\n",
       "   'viewport': {'northeast': {'lat': 46.52033548029151,\n",
       "     'lng': 6.568949680291502},\n",
       "    'southwest': {'lat': 46.51763751970851, 'lng': 6.566251719708498}}},\n",
       "  'place_id': 'ChIJ4zm3ev4wjEcRShTLf2C0UWA',\n",
       "  'types': ['premise']}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import googlemaps\n",
    "# add your own GOOGLE API KEY HERE!!!\n",
    "key = % env GOOGLE_MAPS_KEY\n",
    "gmaps = googlemaps.Client(key=key)\n",
    "test_epfl = gmaps.geocode('EPFL')\n",
    "test_epfl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a list of possible locations (in this case the list of length 1). So we can loop through the candidates to find the Canton. At `administrative_area_level_1`, we can extract the short code of the Canton (which will correspond to the Canton ID in the geographical JSON data). We will also need to check the country to make sure the university/institution is in Switzerland!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if result is in Switzerland\n",
    "def in_Switzerland(place_info):\n",
    "    for info_dict in place_info['address_components']:\n",
    "        if ('country' in info_dict['types']) and (info_dict['long_name'] == 'Switzerland'):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "in_Switzerland(test_epfl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see EPFL is in Switzerland! If the University/Institution is in Switzerland, we can then parse the output for the Canton at `'administrative_area_level_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VD'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CANTON_TYPE_KEY = 'administrative_area_level_1'\n",
    "\n",
    "# parse the Canton short name\n",
    "def parse_canton(place_candidates):\n",
    "    if (place_candidates == None or len(place_candidates) == 0):\n",
    "        return None\n",
    "    # go through multiple results in given to this function by passing a list of 'geocode' results\n",
    "    for place in place_candidates:\n",
    "        if not in_Switzerland(place):\n",
    "            continue\n",
    "        for info_dict in place['address_components']:\n",
    "            if (CANTON_TYPE_KEY in info_dict['types']) and (info_dict['short_name'] in canton_ids):\n",
    "                return info_dict['short_name']\n",
    "    return None    \n",
    "\n",
    "parse_canton(test_epfl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed that using only the University Long Name is not robust enough. So we will use a combination of the University Long Name, the Institution, and the University Short Name in order to determine the Canton as such:\n",
    "\n",
    "* IF it is a University: try LONG NAME\n",
    "    * IF LONG NAME worked: return Canton ID\n",
    "    * ELSEIF LONG NAME couldn't find a results: try Institution (if it is not NaN)\n",
    "    * IF still no result: try SHORT NAME + \"CH\"\n",
    "    * return NaN if search didn't return a result\n",
    "* ELSE: try Institution\n",
    "    * return Canton ID or NaN if search didn't return a result\n",
    "    \n",
    "We will do this with a dictionary though, so that we don't have to make 49823 queries! So we try all unique University names and for those Universities that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Université de Genève', 'Universität Basel',\n",
       "       'Université de Fribourg', 'Universität Zürich',\n",
       "       'Université de Lausanne', 'Universität Bern',\n",
       "       'Eidg. Forschungsanstalt für Wald,Schnee,Land',\n",
       "       'Université de Neuchâtel', 'ETH Zürich',\n",
       "       'Inst. de Hautes Etudes Internat. et du Dév',\n",
       "       'Universität St. Gallen', 'Weitere Institute',\n",
       "       'Firmen/Privatwirtschaft', 'Pädagogische Hochschule Graubünden',\n",
       "       'EPF Lausanne', 'Pädagogische Hochschule Zürich',\n",
       "       'Universität Luzern',\n",
       "       'Schweiz. Institut für Kunstwissenschaft - SIK',\n",
       "       'SUP della Svizzera italiana', 'HES de Suisse occidentale - HES',\n",
       "       'Robert Walser-Stiftung Bern', 'Paul Scherrer Institut',\n",
       "       'Pädagogische Hochschule St. Gallen',\n",
       "       'Eidg. Anstalt für Wasserversorgung',\n",
       "       'Eidg. Material und Prüfungsanstalt',\n",
       "       'Physikal.-Meteorolog. Observatorium Davos',\n",
       "       'Berner Fachhochschule',\n",
       "       'Swiss Center for Electronics and Microtech.', 'Weitere Spitäler',\n",
       "       'AO Research Institute', 'Allergie- und Asthmaforschung',\n",
       "       'Forschungsinstitut für biologischen Landbau',\n",
       "       'Friedrich Miescher Institute', 'Kantonsspital St. Gallen',\n",
       "       'Forschungsanstalten Agroscope', 'Ente Ospedaliero Cantonale',\n",
       "       'Inst. universit. romand de Santé au Travail',\n",
       "       'Eidg. Hochschulinstitut für Berufsbildung',\n",
       "       'Zürcher Fachhochschule (ohne PH)',\n",
       "       'Università della Svizzera italiana',\n",
       "       'Institut für Kulturforschung Graubünden',\n",
       "       'Fachhochschule Nordwestschweiz (ohne PH)',\n",
       "       'Interkant. Hochschule für Heilpädagogik ZH',\n",
       "       \"Centre de rech. sur l'environnement alpin\",\n",
       "       'Idiap Research Institute', 'Pädagogische Hochschule Bern',\n",
       "       'Institut Universitaire Kurt Bösch',\n",
       "       'Schweizer Paraplegiker Forschung', 'Hochschule Luzern',\n",
       "       'Forschungsinstitut für Opthalmologie',\n",
       "       'Haute école pédagogique du canton de Vaud',\n",
       "       'Fachhochschule Ostschweiz',\n",
       "       'Inst. Suisse de Spéléologie et Karstologie',\n",
       "       'Swiss Institute of Bioinformatics',\n",
       "       'Haute école pédagogique BE, JU, NE',\n",
       "       'Pädagogische Hochschule Luzern', 'Forschungskommission SAGW',\n",
       "       'Istituto Svizzero di Roma',\n",
       "       'Pädag. Hochschule Tessin (Teilschule SUPSI)',\n",
       "       'Haute école pédagogique fribourgeoise',\n",
       "       'Pädagogische Hochschule Schwyz', 'Pädagogische Hochschule Thurgau',\n",
       "       'Biotechnologie Institut Thurgau', 'Fachhochschule Kalaidos',\n",
       "       'Schweizer Kompetenzzentrum Sozialwissensch.',\n",
       "       'Pädagogische Hochschule Wallis',\n",
       "       'Schweiz. Hochschule für Logopädie Rorschach',\n",
       "       'Pädagogische Hochschule Zug', 'Instituto Ricerche Solari Locarno',\n",
       "       'Franklin University Switzerland',\n",
       "       'Pädagogische Hochschule Schaffhausen',\n",
       "       'Pädagogische Hochschule Nordwestschweiz',\n",
       "       'Staatsunabh. Theologische Hochschule Basel',\n",
       "       'Facoltà di Teologia di Lugano',\n",
       "       'Fernfachhochschule Schweiz (Mitglied SUPSI)'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universities = grants_modified_uni.University.dropna().unique()\n",
    "universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_canton(row):\n",
    "    # for universities\n",
    "    if pd.notnull(row.University):\n",
    "        # first try university\n",
    "        canton = parse_canton(gmaps.geocode(row.University))\n",
    "        if canton is not None:\n",
    "            return canton\n",
    "        # try institution if University name didn't work\n",
    "        elif pd.notnull(row.Institution):\n",
    "            canton = parse_canton(gmaps.geocode(row.Institution))\n",
    "        if canton is not None:\n",
    "            return canton\n",
    "        # last resort - combine short name and \"CH\"\n",
    "        else:\n",
    "            canton = parse_canton(gmaps.geocode(str(row.Short)+\"CH\"))\n",
    "    else:  # for research institutes\n",
    "        canton = parse_canton(gmaps.geocode(row.Institution))\n",
    "    return canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GE', 'NaN', 'BS', 'FR', 'ZH', 'LA', 'BE', 'WSL', 'NE', 'ETHZ',\n",
       "       'IHEID', 'SG', 'FINST', 'FP', 'PHGR', 'EPFL', 'nan', 'PHZFH', 'LU',\n",
       "       'SIK-ISEA', 'SUPSI', 'HES-SO', 'RWS', 'PSI', 'PHSG', 'EAWAG',\n",
       "       'EMPA', 'PMOD', 'BFH', 'CSEM', 'ASPIT', 'AORI', 'SIAF', 'FIBL',\n",
       "       'FMI', 'KSPSG', 'AGS', 'EOC', 'IST', 'EHB', 'ZFH', 'USI', 'IKG',\n",
       "       'FHNW', 'HfH', 'CREALP', 'IDIAP', 'PHBern', 'IUKB', 'SPF', 'HSLU',\n",
       "       'IRO', 'HEPL', 'FHO', 'ISSKA', 'SIB', 'HEPBEJUNE', 'PHLU', 'SAGW',\n",
       "       'ISR', 'ASP', 'HEPFR', 'PHSZ', 'PHTG', 'BITG', 'FHKD', 'FORS',\n",
       "       'PHVS', 'SHLR', 'PHZG', 'IRSOL', 'FUS', 'PHSH', 'PHFHNW', 'STHB',\n",
       "       'FTL', 'FFHS'], dtype=object)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grants_modified_uni.Short.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RetriableRequest\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, params, first_request_time, retry_counter, base_url, accepts_clientid, extract_body, requests_kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get_body\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"OVER_QUERY_LIMIT\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mgooglemaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RetriableRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_RetriableRequest\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31m_RetriableRequest\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, params, first_request_time, retry_counter, base_url, accepts_clientid, extract_body, requests_kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get_body\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"OVER_QUERY_LIMIT\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mgooglemaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RetriableRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_RetriableRequest\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31m_RetriableRequest\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, params, first_request_time, retry_counter, base_url, accepts_clientid, extract_body, requests_kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get_body\u001b[0;34m(self, resp)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"OVER_QUERY_LIMIT\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mgooglemaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RetriableRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_RetriableRequest\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-344-3a3374415cc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrants_canton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrants_modified_uni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrants_canton\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Canton'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrants_canton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_canton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4059\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4115\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4116\u001b[0m                     result = lib.reduce(values, func, axis=axis, dummy=dummy,\n\u001b[0;32m-> 4117\u001b[0;31m                                         labels=labels)\n\u001b[0m\u001b[1;32m   4118\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4119\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.reduce (pandas/lib.c:43539)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.Reducer.get_result (pandas/lib.c:33736)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-343-f083e551a91d>\u001b[0m in \u001b[0;36msearch_canton\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# last resort - combine short name and \"CH\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mcanton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_canton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mShort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"CH\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for research institutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcanton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_canton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInstitution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/geocoding.py\u001b[0m in \u001b[0;36mgeocode\u001b[0;34m(client, address, components, bounds, region, language)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"language\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/maps/api/geocode/json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, params, first_request_time, retry_counter, base_url, accepts_clientid, extract_body, requests_kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;31m# Retry request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             return self._get(url, params, first_request_time, retry_counter + 1,\n\u001b[0;32m--> 246\u001b[0;31m                              base_url, accepts_clientid, extract_body)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, params, first_request_time, retry_counter, base_url, accepts_clientid, extract_body, requests_kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;31m# Retry request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             return self._get(url, params, first_request_time, retry_counter + 1,\n\u001b[0;32m--> 246\u001b[0;31m                              base_url, accepts_clientid, extract_body)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, params, first_request_time, retry_counter, base_url, accepts_clientid, extract_body, requests_kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;31m# Retry request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             return self._get(url, params, first_request_time, retry_counter + 1,\n\u001b[0;32m--> 246\u001b[0;31m                              base_url, accepts_clientid, extract_body)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/googlemaps/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, params, first_request_time, retry_counter, base_url, accepts_clientid, extract_body, requests_kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;31m# Jitter this value by 50% and pause.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay_seconds\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mauthed_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_auth_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccepts_clientid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def find_canton(row):\n",
    "#     search_canton\n",
    "#     # if not searched before\n",
    "#     if row.University not in uni_canton_dict:\n",
    "#         search_keys = construct_search_keys(row.University, row.Institution)\n",
    "#         uni_canton_dict[row.University] = search_canton(search_keys)\n",
    "#         print(row.University + \" \" + uni_canton_dict[row.University])\n",
    "#     return uni_canton_dict[row.University]\n",
    "\n",
    "grants_canton = grants_modified_uni.copy()\n",
    "grants_canton['Canton'] = grants_canton.apply(search_canton, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    396\n",
       "ZH      28\n",
       "VD      14\n",
       "BS      13\n",
       "GE      11\n",
       "BE      11\n",
       "FR       9\n",
       "SG       8\n",
       "LU       8\n",
       "TI       6\n",
       "TG       5\n",
       "NE       5\n",
       "SH       3\n",
       "GR       2\n",
       "AG       2\n",
       "OW       1\n",
       "ZG       1\n",
       "SO       1\n",
       "SZ       1\n",
       "BL       1\n",
       "Name: Canton, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grants_canton.Canton.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute grants by canton, we need to find the corresponding Canton for a particular \"Institute\".\n",
    "\n",
    "We will first use the **Geonames API** as this was suggested by the assignment but then revert to the results of the **GoogleMaps API** as the latter is able to map more of the \"Institutes\". \n",
    "\n",
    "### Geonames API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uni_canton = pd.DataFrame(columns=['University','Canton'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def canton_in_CH(result):\n",
    "    for i in range(len(result)):\n",
    "        if(result['geonames'][i]['countryName']=='Switzerland'):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = 'http://api.geonames.org/searchJSON?'\n",
    "\n",
    "def canton_get(uni):\n",
    "    paraload = {'q':uni,'username':'shiyuenie'}\n",
    "    r = requests.get(URL, params=paraload)\n",
    "    result = r.json()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geonames': [], 'totalResultsCount': 0}"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canton_get(\"AGRIDEA, CH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-a2f9b20fb3c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mucount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstitutes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# search full name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0muni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstitutes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mucount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanton_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muni\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geonames'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcanton_in_CH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eric/anaconda/envs/py35/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for ucount in range(len(institutes)): # search full name\n",
    "    uni = institutes[0][ucount]\n",
    "    result = canton_get(uni)\n",
    "    if (result['geonames'] != []):\n",
    "        if (canton_in_CH(result)):\n",
    "            uni_canton.loc[ucount] = [uni,result['geonames'][0]['adminName1']]\n",
    "        else:\n",
    "            uni_canton.loc[ucount] = [uni,'Not Found']   \n",
    "    else:\n",
    "        uni_canton.loc[ucount] = [uni,'Not Found']\n",
    "    \n",
    "uni_canton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#uni_name=uni_name.replace({r'\\s+': '&'}, regex=True)\n",
    "\n",
    "for ucount in range(len(uni_name)):\n",
    "    if (uni_canton.loc[:,'Canton'][ucount] == 'Not Found'): # search with seperate parts\n",
    "        uni_full = uni_name['Full Name'][ucount] \n",
    "        uni_short = uni_name['Short Name'][ucount] \n",
    "        result = canton_get(uni_full) # search part 1\n",
    "        if (result['geonames'] != []):\n",
    "            if(canton_in_CH(result)):\n",
    "                uni_canton.loc[ucount] = [uni,result['geonames'][0]['adminName1']]\n",
    "            else:\n",
    "                result = canton_get(uni_short) # search part 2 \n",
    "                if (result['geonames'] != []):\n",
    "                    if(canton_in_CH(result)):\n",
    "                        uni_canton.loc[ucount] = [uni,result['geonames'][0]['adminName1']]\n",
    "        \n",
    "uni_canton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_canton[uni_canton['Canton'] != \"Not Found\"]\n",
    "\n",
    "for ucount in range(len(uni_test)): # search full name wit &\n",
    "    uni = uni_test[0][ucount]\n",
    "    result = canton_get(uni)\n",
    "    if (result['geonames'] != []):\n",
    "        if (canton_in_CH(result)):\n",
    "            uni_canton.loc[ucount] = [uni,result['geonames'][0]['adminName1']]\n",
    "    \n",
    "uni_canton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(uni_canton.loc[:,'Canton']=='Not Found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_canton[uni_canton['Canton'] != \"Not Found\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(uni_canton.loc[:,'Canton']!='Not Found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleMaps API\n",
    "\n",
    "We use a Python [API wrapper](https://github.com/googlemaps/google-maps-services-python) for GoogleMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to install the wrapper: pip install -U googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "\n",
    "# Key omitted due to security concerns on Github\n",
    "# API_KEY = 'AIzaSyC2-TxJBHd-X8RnFh3-a6Y9hXri7WpktHE'\n",
    "key = % env GOOGLE_MAPS_KEY\n",
    "#########################'\n",
    "\n",
    "gmaps = googlemaps.Client(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We try a sample search to obtain the structure of reply\n",
    "test_epfl = gmaps.geocode('EPFL Switzerland')\n",
    "test_epfl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We notice that canton information is returned in 'administrative_area_level_1' field. long_name gives the full name of the canton, short_name gives the abbrevation, the same as the id used in geometry json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CANTON_TYPE_KEY = 'administrative_area_level_1'\n",
    "    \n",
    "def place_in_CH(place_info):\n",
    "    for info_dict in place_info['address_components']:\n",
    "        if info_dict['long_name'] == 'Switzerland':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def parse_canton(place_candidates):\n",
    "    if (place_candidates == None or len(place_candidates) == 0):\n",
    "        return None\n",
    "    \n",
    "    for place in place_candidates:\n",
    "        if not place_in_CH(place):\n",
    "            continue\n",
    "        for info_dict in place['address_components']:\n",
    "            if (CANTON_TYPE_KEY in info_dict['types']) and (info_dict['short_name'] in canton_ids):\n",
    "                return info_dict['short_name']\n",
    "    \n",
    "    return None    \n",
    "\n",
    "parse_canton(test_epfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_search_keys(university, institution):\n",
    "    \n",
    "    def keys_with(x):\n",
    "        keys = []\n",
    "        keys.append(x)\n",
    "        keys.append(x + ', Switzerland')\n",
    "        keys.append(x + ', CH')\n",
    "        return keys\n",
    "    \n",
    "    uni_full_name, uni_short_name = university.rsplit('-',1)\n",
    "\n",
    "    keys = []   \n",
    "    keys += keys_with(university)\n",
    "    keys += keys_with(uni_full_name)\n",
    "    \n",
    "    if institution != None:\n",
    "        keys += keys_with(str(institution))\n",
    "    if uni_short_name != None:\n",
    "        keys += keys_with(uni_short_name)\n",
    "    return keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_canton(keys):\n",
    "    for key in keys:\n",
    "        resp = gmaps.geocode(key)\n",
    "        canton = parse_canton(resp)\n",
    "        if canton != None:\n",
    "            return canton\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# intialize uni_canton_dict from file\n",
    "# uni_canton_dict maps university to canton\n",
    "uni_canton_df = pd.read_csv('uni-canton.csv', encoding='utf-8')\n",
    "uni_canton_df.set_index('University', inplace=True)\n",
    "uni_canton_dict = uni_canton_df.to_dict()['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_canton(row):\n",
    "    # if not searched before\n",
    "    if row.University not in uni_canton_dict:\n",
    "        search_keys = construct_search_keys(row.University, row.Institution)\n",
    "        uni_canton_dict[row.University] = search_canton(search_keys)\n",
    "        print(row.University + \" \" + uni_canton_dict[row.University])\n",
    "    return uni_canton_dict[row.University]\n",
    "\n",
    "df = data.copy()\n",
    "df['Canton'] = df.apply(find_canton, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# uni_canton_df = pd.DataFrame.from_dict(uni_canton_dict, orient=\"index\")\n",
    "# uni_canton_df.index.name = 'University'\n",
    "# uni_canton_df.to_csv('uni-canton.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df['Canton'] = df.apply(find_canton, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data-with-canton.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "found_rate = pd.notnull(df['Canton']).sum() / len(df['Canton'])\n",
    "found_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually handle missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fow now, we simply ignore the missing records.\n",
    "\n",
    "#  Compute grants by canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "canton_grants_df = df[['Approved Amount', 'Canton']].groupby(['Canton']).mean()\n",
    "canton_grants_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add missing data\n",
    "for canton_id in canton_ids:\n",
    "    if canton_id not in canton_grants_df['Canton'].values:\n",
    "        canton_grants_df = canton_grants_df.append({'Canton':canton_id, 'Approved Amount': 0.0}, ignore_index=True)\n",
    "\n",
    "canton_grants_df = canton_grants_df.sort_values(by=['Approved Amount'], ascending=False)\n",
    "canton_grants_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization\n",
    "##  Draw grants map by canton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map = folium.Map(location=[46.82244,8.22410], zoom_start=8)\n",
    "map.choropleth(data=canton_grants_df,\n",
    "               columns=['Canton', 'Approved Amount'], \n",
    "               key_on='feature.id', \n",
    "               geo_path=CH_GEO_JSON, \n",
    "               topojson='objects.cantons', \n",
    "               fill_color='YlOrRd'\n",
    "               )\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** TODO **: The map cannot be displayed on Github. To view the map, you have to run this cell locally with Jupyter Notebook. To facilitate code reviewing, we may add an additionaly snapshot of the map here."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
